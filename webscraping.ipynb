{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python web scraping to fetch companies data from [ambitionbox.com/list-of-companies](https://www.ambitionbox.com/list-of-companies?page=1) using BeautifulSoup library.\n",
    "\n",
    "Web pages contains data about different companies.\n",
    "    \n",
    "\n",
    "    Columns which are required for analysis:\n",
    "        -name\n",
    "        -rating\n",
    "        -review\n",
    "        -type\n",
    "        -location\n",
    "        -age\n",
    "        -employee_count\n",
    "        -description\n",
    "    \n",
    "We need to convert these data of  into pd dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web page 1\n",
    "url = 'https://www.ambitionbox.com/list-of-companies?page=1'\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}\n",
    "# headers for accessing the web page\n",
    "req = requests.get(url=url,headers=headers)\n",
    "html = req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1, shrink-to-fit=no\" name=\"viewport\"/>\n",
      "  <meta content=\"5; URL='/list-of-companies?page=1&amp;bm-verify=AAQAAAAH_____7QChgEqMsM4-mxyub-ysKWbRALxtqx_Qq388Qo24N_R7Zs6aq6w0O8RJoIDjsQredfy3pAuAcLIBv7c82AeXkYz5ol6lXa8jXWC7aG6NJsXWGGCv5BioD6osDMv1CbvfbWqcEBRYWajHCwppNUqs0SbJcKNxDp5y8TDy7Nz0qUYHCJReGjm5AXwzkFFKQ9d_3SqQ-vKA3GoqW3wB_xmXD7bZjpoUBuPt4H7Z0KP065ImkLGJ5wEGfH6z087wsCLDvHYH3BQyGtQYxZsmhleNWLxdw'\" http-equiv=\"refresh\">\n",
      "   <title>\n",
      "   </title>\n",
      "   <script>\n",
      "    var i = 1685560921;\n",
      "        var j = i + Number(\"8436\" + \"47882\");\n",
      "   </script>\n",
      "  </meta>\n",
      " </head>\n",
      " <noscript>\n",
      "  <iframe src=\"\" style=\"border: none; height: 100%; width: 100%;\">\n",
      "  </iframe>\n",
      " </noscript>\n",
      " <script>\n",
      "  var xhr = new XMLHttpRequest();\n",
      "          xhr.withCredentials = true;\n",
      "          xhr.addEventListener(\"loadend\", function() {\n",
      "              try {\n",
      "                  var data = JSON.parse(xhr.responseText);\n",
      "                  if (data.hasOwnProperty('reload')) {\n",
      "                      if (data[\"reload\"] == true) {\n",
      "                        window.location.replace(window.location.href.replace(/[&?]bm-verify=[^#]*/, \"\"));\n",
      "                        if(window.location.hash){\n",
      "                          window.location.reload();\n",
      "                        }\n",
      "                      }\n",
      "                  } else if (data.hasOwnProperty('location')) {\n",
      "                      window.location.replace(data[\"location\"]);\n",
      "\n",
      "                  } else {\n",
      "                      window.location.reload();\n",
      "                  }\n",
      "              } catch (e) {\n",
      "                  var data = {}\n",
      "                  window.location.reload();\n",
      "              }\n",
      "          });\n",
      "          xhr.open(\"POST\", \"/_sec/verify?provider=interstitial\", false);\n",
      "          xhr.setRequestHeader(\"Content-Type\", \"application/json\");\n",
      "          xhr.send(JSON.stringify({\n",
      "              \"bm-verify\": \"AAQAAAAH/////y50h6yPS2owTB3wc+i96idfxbbliF1m74YRAPwT/7/Q8VqmQv6RTJqb1MF3816QlQMcozi0AfKvyIGrDV1kAi84X0xbjj0OulTOF8ku2Wp0JRJa2BOOAOkRtd7T581LsmMeMw3PdeD4bxCJoxagD/RHwd3SSCee2z9R9owEoq99zz96CgOcsFOjwDS2bcaS+fZcYTFBopbexcP5Ra1JvnRK+XkayRhYCTOhPvy7QXQCFxMnL3TTJxpQjiWSLYNcAvTuyLaRzDLdmz3rNEE1WXjO/FdfZfi8h1jHStbDKvZao08=\",\n",
      "              \"pow\": j\n",
      "          }));\n",
      " </script>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting html to soup object for data parsing\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "# printing as html code viewer\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # h1 tags\n",
    "# soup.findAll('h1')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping web pages\n",
    "company_data_list = [] # list of each_company's data\n",
    "page_no = 1 # web page_no: 1\n",
    "\n",
    "while True:\n",
    "    url = 'https://www.ambitionbox.com/list-of-companies?page={}'.format(page_no)\n",
    "    headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}\n",
    "    # headers for accessing the web page\n",
    "    req = requests.get(url=url,headers=headers)\n",
    "    html = req.text\n",
    "    soup= BeautifulSoup(html)\n",
    "\n",
    "    # if there are no \n",
    "    if soup.find('div','error-page'):\n",
    "        print('There is no data in further web-page.')\n",
    "        print('Total web pages scraped = ' + str(page_no-1))\n",
    "        print('Total no. of companies = ' + str(len(company_data_list)))\n",
    "        break\n",
    "\n",
    "    companies = soup.findAll('div','company-content-wrapper') # companies data in a list\n",
    "    # len(companies) #30\n",
    "\n",
    "    for company in companies:\n",
    "        # h2 tags for fetching name\n",
    "        name = company.find('h2').text.strip() # '\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tTCS\\n\\t\\t\\t\\t\\t\\t\\t\\t' to 'TCS'\n",
    "\n",
    "        # p tags for rating\n",
    "        rating = company.find('p','rating').text.strip() # stripping the tab & new line characters \n",
    "        \n",
    "        # a tags for review\n",
    "        review = company.find('a','review-count').text.strip().strip('()').split()[0] # (51.7k Reviews) to 51.7k\n",
    "\n",
    "        # p tags for type,location,age,employee_count\n",
    "        info = company.findAll('p','infoEntity') # list of each company's type,location,age &memployee_count\n",
    "        try:\n",
    "            type = info[0].text.strip()\n",
    "        except:\n",
    "            type = ''\n",
    "        try:\n",
    "            location = info[1].text.strip()\n",
    "        except:\n",
    "            location = ''\n",
    "        try:\n",
    "            age = info[2].text.strip() # '55 years old' to 55\n",
    "        except:\n",
    "            age = ''\n",
    "        try:\n",
    "            employee_count = info[3].text.strip()\n",
    "        except:\n",
    "            employee_count = 0\n",
    "\n",
    "        # p tag for description\n",
    "        try:\n",
    "            description = company.find('p','description').text.strip()\n",
    "        except:\n",
    "            description = ''\n",
    "        company_dict = {'name':     name,\n",
    "                        'rating':   rating,\n",
    "                        'review':   review,\n",
    "                        'rating':   rating,\n",
    "                        'type':     type,\n",
    "                        'location': location,\n",
    "                        'age':      age,\n",
    "                        'employee_count': employee_count,\n",
    "                        'description': description}\n",
    "\n",
    "        company_data_list.append(company_dict)\n",
    "\n",
    "    page_no += 1 \n",
    "\n",
    "df = pd.DataFrame(company_data_list)\n",
    "df.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9959 entries, 0 to 9958\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   name            9959 non-null   object\n",
      " 1   rating          9959 non-null   object\n",
      " 2   review          9959 non-null   object\n",
      " 3   type            9959 non-null   object\n",
      " 4   location        9959 non-null   object\n",
      " 5   age             9959 non-null   object\n",
      " 6   employee_count  9959 non-null   object\n",
      " 7   description     9959 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 622.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "291ac05ecce300c024e84a1ef5acdf1252f6fca83188103fe58a5b67eb0dded4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
